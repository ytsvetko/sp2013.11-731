#!/usr/bin/env python
import optparse
import sys
from collections import defaultdict

optparser = optparse.OptionParser()
optparser.add_option("-b", "--bitext", dest="bitext", default="data/dev-test-train.de-en", help="Parallel corpus (default data/dev-test-train.de-en)")
optparser.add_option("-t", "--threshold", dest="threshold", default=0.5, type="float", help="Threshold for aligning with Dice's coefficient (default=0.5)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint, type="int", help="Number of sentences to use for training and alignment")
optparser.add_option("-d", "--delta", dest="delta", default=0.0005, type="float", help="EM stopping condition")

(opts, _) = optparser.parse_args()

def Model1(bitext):
  def MakeUniformProbs():
    alignments = defaultdict(float) # key (f, e), value - alignment prob
    for f_sent, e_sent in bitext:
      for e_word in e_sent:
        for f_word in f_sent:
          alignments[(f_word, e_word)] = 1.0
    for k in alignments.iterkeys():
      alignments[k] = alignments[k]/len(alignments) 
    return alignments

  def SingleIteration(alignments):
    # initialize
    count = defaultdict(float) 
    total = defaultdict(float)
    for f_sent, e_sent in bitext:
      # compute normalization
      sum_total = {}
      for e_word in e_sent:
        sum_total[e_word] = 0
        for f_word in f_sent:
          sum_total[e_word] += alignments[(f_word, e_word)]
      # collect counts  
      for e_word in e_sent:
        for f_word in f_sent:
          count[(f_word, e_word)] += alignments[(f_word, e_word)] / sum_total[e_word]
          total[f_word] += alignments[(f_word, e_word)] / sum_total[e_word]
    # estimate probabilities
    new_alignments = defaultdict(float)
    delta = 0.0
    for f_word, e_word in count.iterkeys():
      new_alignments[(f_word, e_word)] = count[(f_word, e_word)]/total[f_word]
      delta += abs(new_alignments[(f_word, e_word)] - alignments[(f_word, e_word)])
    return new_alignments, delta/len(new_alignments) 

  alignments = MakeUniformProbs()
  for i in range(10):
    alignments, delta = SingleIteration(alignments)
    sys.stderr.write( str(delta) + "\n")
    if delta <= opts.delta:
      return alignments


def Dice(bitext):
  f_count = defaultdict(int)
  e_count = defaultdict(int)
  fe_count = defaultdict(int)
  for f, e in bitext:
    for f_i in set(f):
      f_count[f_i] += 1
      for e_j in set(e):
        fe_count[(f_i,e_j)] += 1
    for e_j in set(e):
      e_count[e_j] += 1

  dice = defaultdict(int)
  for f_i, e_j in fe_count.keys():
    dice[(f_i,e_j)] = 2.0 * fe_count[(f_i, e_j)] / (f_count[f_i] + e_count[e_j])
  return dice    

def ParseInput():
  return [[sentence.lower().strip().split() for sentence in pair.split(' ||| ')] for pair in open(opts.bitext)][:opts.num_sents]

def PrintOutput(bitext, alignment_probs):
  for (f, e) in bitext:
    for (i, f_i) in enumerate(f): 
      for (j, e_j) in enumerate(e):
        if alignment_probs[(f_i,e_j)] >= opts.threshold:
          sys.stdout.write("%i-%i " % (i,j))
    sys.stdout.write("\n")
  
def main():
  bitext = ParseInput()
  #alignment_probs = Dice (bitext)
  alignment_probs = Model1(bitext)
  PrintOutput(bitext, alignment_probs)

if __name__ == '__main__':
  main()
